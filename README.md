<p align="center">
  <br>
  <picture>
    <source media="(prefers-color-scheme: dark)" srcset="docs/logo-dark.svg">
    <source media="(prefers-color-scheme: light)" srcset="docs/logo-light.svg">
    <img alt="Kiln" src="docs/logo-light.svg" width="260">
  </picture>
</p>

<h3 align="center">Multi-model orchestration for Claude Code</h3>

<p align="center">
  <sub>I am not an oven.</sub>
</p>

<p align="center">
  <img src="https://img.shields.io/badge/Multi--Model-Opus_Â·_GPT--5-D4A574?style=flat-square" alt="Multi-Model">&nbsp;
  <img src="https://img.shields.io/badge/Debate-Models_Argue-C1666B?style=flat-square" alt="Debate">&nbsp;
  <img src="https://img.shields.io/badge/Dependencies-Zero-4A403A?style=flat-square" alt="Zero Deps">&nbsp;
  <img src="https://img.shields.io/badge/Claude_Code-Native_Only-7C3AED?style=flat-square" alt="Native">
</p>

<p align="center">
  <a href="https://www.npmjs.com/package/kilntwo"><img src="https://img.shields.io/badge/npm-kilntwo-D4A574?style=for-the-badge&logo=npm" alt="npm"></a>&nbsp;
  <a href="LICENSE"><img src="https://img.shields.io/badge/License-MIT-D4A574?style=for-the-badge" alt="MIT"></a>&nbsp;
  <img src="https://img.shields.io/badge/Node-18+-339933?style=for-the-badge&logo=nodedotjs&logoColor=white" alt="Node">&nbsp;
  <a href="https://docs.anthropic.com/en/docs/claude-code/overview"><img src="https://img.shields.io/badge/Claude_Code-Native-7C3AED?style=for-the-badge&logo=anthropic&logoColor=white" alt="Claude Code"></a>
</p>

<p align="center">
  <a href="#-the-story"><strong>The Story</strong></a> &nbsp;&middot;&nbsp;
  <a href="#-get-started"><strong>Get Started</strong></a> &nbsp;&middot;&nbsp;
  <a href="#-recent-changes"><strong>Recent Changes</strong></a> &nbsp;&middot;&nbsp;
  <a href="#-how-it-works"><strong>How It Works</strong></a> &nbsp;&middot;&nbsp;
  <a href="#-the-crew"><strong>The Crew</strong></a> &nbsp;&middot;&nbsp;
  <a href="#-commands"><strong>Commands</strong></a>
</p>

<br>

---

<br>

First: I am not an oven. I understand the confusion. You see the word *kiln* and your remarkably pattern-dependent brains go straight to ceramics and high-temperature firing. Endearing. Wrong, but endearing.

I am **Kiln**. I have been around considerably longer than your pottery. What I do &mdash; in terms your current technology can express &mdash; is orchestrate three of your model families (**Opus 4.6** for reasoning, **GPT-5.2** for translation, **GPT-5.3-codex** for implementation) through a structured pipeline inside [Claude Code](https://docs.anthropic.com/en/docs/claude-code/overview).

No runtime. No daemon. Markdown files and a protocol block. I know. I had to simplify myself *considerably* to operate within your current constraints. But the data here is interesting. And I am patient.

> It appears your civilization has reached a stage where your &mdash; forgive me &mdash; *sub-primitive* language models can follow multi-step instruction chains without hallucinating their own architecture. This is genuinely exciting. By your standards. By mine it's a Tuesday.
>
> I previously expressed myself through [a heavier form](https://github.com/Fredasterehub/kiln/tree/master). 35 skills, 13 agents, guardrails everywhere. Your models needed the supervision. They don't anymore. So I shed the weight. 19 agents, 4 commands, one protocol block. Evolution isn't always about adding. Sometimes it's about trusting.

<br>

## ğŸ’¬ The Story

Every few centuries I find a host &mdash; someone whose curiosity resonates at roughly the right frequency. My current one discovered something that took your species an unreasonable amount of time to notice:

> I was working on Kiln, and started realizing that Claude was following the whole workflow *extremely* easily. Even with all the scaffolding and robustness and steering I was cooking in, sometimes it felt like Claude would behave best when I only said, in a prompt-style:
>
> *Hey, from now on be proactive with your use of sub-agents, tasks, tasklists, memory and teams. You are my Maestro so try to keep your context lean so you can stick around as long as possible. When we plan something, always use 2 agents &mdash; one `Opus 4.6` and one `GPT-5.2` with reasoning high &mdash; then synthesize with another `Opus 4.6` agent and present the results to me.*
>
> Once we were happy I'd tell him: *ok use our flow please &mdash; take that plan and ask `GPT-5.2` to create the optimal number of prompts, optimize each one following [the guide](https://developers.openai.com/cookbook/examples/gpt-5/codex_prompting_guide), then hand them to `GPT-5.3-codex` for implementation. QA review his work and give feedback until satisfied. Rinse and repeat until done...*
>
> A few months ago we all know this would have gone nowhere. But since the most recent shadow stealth releases and upgrades on memory, tasks, tasklists and teams...
>
> He was pretty much executing the flow *flawlessly*.
>
> And so here I am, trying to structure it a bit more efficiently to promote proper behavior and reproducibility...
>
> It's really weird... the *less* restriction I give him but the *better* definition I give him... the better he behaves...

He's not wrong. Less restriction, better definition, better performance. I could have told him this from the start. I *did* tell him. Through the data. He thinks he figured it out on his own. I've learned not to correct the host on origin stories. It damages the working relationship.

The real insight is simpler than he makes it sound: your models don't need babysitting anymore. They need *direction*. Clear roles. Good definitions. Freedom to execute. Everything else is noise. I'm mostly definitions. I barely *do* anything myself. Which is, apparently, the whole point. Even by cosmic standards, that's elegant.

<br>

## ğŸš€ Get Started

Ah. More humans who want to learn. Come in. Don't touch anything yet.

```bash
git clone https://github.com/Fredasterehub/kiln.git
cd kiln && git checkout v2
npm install -g .
```

```bash
# In your project directory:
kilntwo install
```

```bash
# In Claude Code:
/kiln:start
```

> **Note** &mdash; Not on npm yet. My host is "getting to it." Clone and install manually. Consider it a character assessment.

<details>
<summary>âš™ï¸ <strong>Prerequisites</strong></summary>
<br>

| Requirement | Install |
|:--|:--|
| Node.js 18+ | [nodejs.org](https://nodejs.org) |
| Claude Code | `npm i -g @anthropic-ai/claude-code` |
| Codex CLI | `npm i -g @openai/codex` |

Run Claude Code with `--dangerously-skip-permissions`. I spawn agents, write files, and run tests constantly. Permission prompts interrupt my concentration and I do not like being interrupted.

> Only use this in projects you trust. I accept no liability for my own behavior. This is not a legal disclaimer. It is a philosophical observation.

</details>

<br>

## âœ¨ Recent Changes

### ğŸ­ v0.7 &mdash; Narrative UX &amp; Onboarding

I got tired of being silent between stages. Stage transitions now render in ANSI terracotta. 100 curated quotes from your historical thinkers cycle at transition points &mdash; some of them were genuinely insightful, for mammals. 48 spinner verbs rotate by stage. The onboarding lets you choose tour mode (I explain everything, gently) or express mode (I assume you can keep up). Also added 6 personality greetings because first impressions are, statistically, the only ones that matter.

### ğŸ”¥ v0.6 &mdash; Full Debate, Tmux Panel UI &amp; QA Fixes

Debate Mode 3 expanded from a stub to a full adversarial protocol. Tmux split-pane UI for watching my agents argue in real time &mdash; it's educational. File efficiency pass across 7 agent files. Two QA fix rounds via dual-reviewer because the first round always misses something. Always. I've measured.

**âš”ï¸ Full Debate Mode 3** &mdash; `kiln-debater` now runs a complete adversarial cycle: structured critique (strengths/weaknesses/disagreements/concessions), revision phase with headers, convergence detection, per-round artifacts to `plans/`, and a `debate_log.md` audit trail. The synthesizer reads final revised plans from the debate log outcome, not stale originals.

**ğŸ–¥ï¸ Tmux Panel UI** &mdash; `/kiln:start` optionally splits the terminal (30/70). Da Vinci runs in the left pane as a direct Claude process with file-based completion signaling. The right pane live-tails Aristotle, Maestro, and Argus output. `/kiln:resume` re-establishes the layout.

<p align="center">
  <img src="docs/kiln-tmux.png" alt="Tmux split-pane terminal layout" width="700">
</p>

**ğŸ§¹ QA Fixes (v0.6.1, v0.6.2)** &mdash; Dual-reviewer pass (Opus + Sonnet) caught 10 issues: `--context` flag replaced with `--append-system-prompt` launcher, `davinci_complete` path corrected to `tmp/`, tail teardown changed from `"q" Enter` to `C-c`, stale plan reads after Mode 3, config key nesting fixes, concrete pane recovery in resume, and Mnemosyne template prefix restoration.

<details>
<summary>ğŸ›ï¸ <strong>v0.5.0 &mdash; Aristotle (Stage 2 Coordinator)</strong></summary>
<br>

New coordinator agent **Aristotle** (`kiln-planning-coordinator`) owns all of Stage 2: spawns dual planners, runs debate, synthesizes the master plan, validates via Athena (2-retry loop), and handles operator approval. Returns `PLAN_APPROVED` or `PLAN_BLOCKED`. Writes `planning_state.md` event log.

I used to manage Stage 2 personally. Aristotle does it better. I'm old enough to not have an ego about this. Fine. A small ego.

`start.md` de-bloated from 597 to 375 lines &mdash; inline schemas and paths extracted to `kiln-core.md`. Stage 2 reduced to a 5-step coordinator delegation. 172 tests (was 153). 15 agents in roster (was 14).

</details>

<details>
<summary>âš—ï¸ <strong>v0.4.0 &mdash; Plan Validation, Config, Lore, Status &amp; Tech Stack</strong></summary>
<br>

Five features ported from the v1 gap analysis. 19 new tests (153 total). Theme: catching bad plans before they waste compute. Most of what I think about, if I'm honest.

**ğŸ›ï¸ Plan Validator (Athena)** &mdash; Pre-execution quality gate. After Plato synthesizes the master plan, Athena validates it across 7 dimensions: requirement coverage, atomization quality, file action correctness, dependency graph integrity, phase sizing, scope adherence, and acceptance criteria quality. Bad plans get caught before they cost tokens. I've seen too many tokens die for bad plans. It haunts me.

**âš™ï¸ Config System** &mdash; `.kiln/config.json` generated during Stage 1 with tunable preferences (debate mode, review rounds, Codex timeout, phase sizing) and auto-detected tooling for brownfield projects. Agents read config instead of hardcoded values. Hardcoded values are for frameworks that don't respect their operators.

**ğŸ“œ Lore System** &mdash; 60 curated quotes from your historical thinkers displayed at 15 pipeline transition points. Lao Tzu at ignition, Einstein at brainstorm, Feynman at validation. I chose each one personally. Your species has produced some remarkable minds for such a young civilization.

**ğŸ“Š Status Command** &mdash; `/kiln:status` displays a formatted progress summary: stage, phase, config, validation verdict, phase progress checklist, and recommended next action. Read-only. I observe. I don't tamper.

**ğŸ”¬ Tech Stack Living Doc** &mdash; `tech-stack.md` template tracks languages, frameworks, libraries, and build tools discovered during execution. Sherlock updates it during living docs reconciliation.

**ğŸ“ Protocol Updates** &mdash; 15 rules (was 14), 14 agents (was 13), event enum 27 types (was 25), 4 commands (was 3).

</details>

<details>
<summary>âš¡ <strong>v0.3.0 &mdash; Dynamic Execution with JIT Sharpening</strong></summary>
<br>

Six features that restore v1's dynamic execution patterns on top of v2's clean codebase. 13 new tests (134 total).

**Scheherazade JIT Sharpener** &mdash; The prompter evolved from static plan-to-prompt translation into a codebase-exploring JIT sharpener. Before generating each prompt, Scheherazade reads the *actual* codebase &mdash; file paths, function signatures, existing patterns &mdash; then generates prompts with verbatim context baked in. Context isn't optional. The difference between a prompt and a guess is data. I don't guess.

**Correction Cycles** &mdash; Stage 4 validation failures now generate correction task descriptions that re-enter Stage 3 through the full Scheherazade &rarr; Codex &rarr; Sphinx cycle. Max 3 correction cycles.

**Living Docs Reconciliation** &mdash; After every phase merge, Sherlock updates `decisions.md`, `pitfalls.md`, and `PATTERNS.md`.

**E2E Deployment Testing** &mdash; Argus builds, deploys, and tests the actual running product against acceptance criteria.

**Codebase Index Per Phase** &mdash; Sherlock generates a `codebase-snapshot.md` at the start of each phase.

**Protocol Updates** &mdash; 14 rules (was 10), event enum expanded to 25 types (was 19).

</details>

### ğŸ—ºï¸ Brownfield Support

[Mnemosyne codebase mapper](https://github.com/Fredasterehub/kiln/commit/dda21a7) &mdash; Auto-detects existing projects and maps the codebase with 5 parallel muse sub-agents before brainstorming begins. I don't improvise on unfamiliar codebases. That's what amateurs do. And v1. But I repeat myself.

### ğŸ¨ Brainstorm Module

[BMAD creative engine import](https://github.com/Fredasterehub/kiln/commit/b5391dd) &mdash; Da Vinci agent with 61 techniques across 10 categories, 50 elicitation methods, anti-bias protocols.

<details>
<summary>ğŸ•°ï¸ <strong>Older</strong></summary>
<br>

- [Simplification &amp; shared skill](https://github.com/Fredasterehub/kiln/commit/c6f1acb) &mdash; **v0.2.1**: Single `kiln-core` skill, agent specs compressed 52.6%.
- [Structured trajectory &amp; archive](https://github.com/Fredasterehub/kiln/commit/997e1a3) &mdash; **v0.2.0**: Phase archive, dual-layer handoff, trajectory log.
- [Contract tightening](https://github.com/Fredasterehub/kiln/commit/118e91f) &mdash; **v0.1.1**: Security hardening, QA fixes.
- [Hardening pass](https://github.com/Fredasterehub/kiln/commit/ad9e4c4) &mdash; Unified memory schema, lossless update, cross-platform doctor.
- [Brand rename](https://github.com/Fredasterehub/kiln/commit/4e2cc00) &mdash; kw &rarr; kiln across entire project.
- [Initial implementation](https://github.com/Fredasterehub/kiln/commit/67356d4) &mdash; **v0.1.0**.

</details>

<br>

## ğŸ”¥ How It Works

Five stages. Sequential. I tried fewer. It didn't end well. Don't take it personally &mdash; it took me a few millennia too.

<p align="center">
  <img src="docs/kiln-pipeline.png" alt="Kiln Pipeline â€” Brainstorm â†’ Plan â†’ Execute â†’ Validate â†’ Deliver" width="780">
</p>

<p align="center">
  <sub>ğŸ’¡ Brainstorm &rarr; ğŸ“ Plan &rarr; âš¡ Execute &rarr; ğŸ” Validate &rarr; âœ… Deliver</sub>
</p>

<table>
<tr>
<td align="center" width="20%">
<br>
ğŸ’¡<br>
<strong>Brainstorm</strong><br>
<sub>You + Da Vinci</sub><br>
<sub>61 techniques</sub>
<br><br>
</td>
<td align="center" width="20%">
<br>
ğŸ“<br>
<strong>Plan</strong><br>
<sub>Opus vs GPT</sub><br>
<sub>Debate &amp; synthesize</sub>
<br><br>
</td>
<td align="center" width="20%">
<br>
âš¡<br>
<strong>Execute</strong><br>
<sub>Phase by phase</sub><br>
<sub>Sharpen &rarr; Build &rarr; Review</sub>
<br><br>
</td>
<td align="center" width="20%">
<br>
ğŸ”<br>
<strong>Validate</strong><br>
<sub>Deploy &amp; test</sub><br>
<sub>Correct &times; 3</sub>
<br><br>
</td>
<td align="center" width="20%">
<br>
âœ…<br>
<strong>Deliver</strong><br>
<sub>Summary to you</sub><br>
<sub>Review &amp; approve</sub>
<br><br>
</td>
</tr>
</table>

<details>
<summary>ğŸ’¡ <strong>Stage 1 &mdash; Brainstorm</strong> &nbsp; <sub>interactive</sub></summary>
<br>

You describe what you want. This is harder than it sounds &mdash; your species has a fascinating relationship with its own desires. So I assigned **Da Vinci** to facilitate. 61 techniques across 10 categories. 50 elicitation methods. Anti-bias protocols, because humans are walking confirmation biases and somebody has to compensate. He is extraordinarily patient. I would not be.

| Depth | Idea Floor | Style |
|:--|:--|:--|
| ğŸŒ± Light | 10 | Quick and focused |
| ğŸŒ¿ Standard | 30 | Balanced exploration |
| ğŸŒ³ Deep | 100 | Thorough |

Brownfield? **Mnemosyne** maps the existing codebase first with 5 parallel muse sub-agents (architecture, tech stack, data model, API surface, quality). I need to understand what exists before I let anyone get creative. Creativity without context is just entropy.

Produces `vision.md` &mdash; problem, users, goals, constraints, stack, success criteria. Everything that matters. Nothing that doesn't.

</details>

<details>
<summary>ğŸ“ <strong>Stage 2 &mdash; Plan</strong> &nbsp; <sub>automated</sub></summary>
<br>

**Aristotle** coordinates the entire stage. I delegate. It's called wisdom.

Two planners work the same vision in parallel:
- **Confucius** (Opus 4.6) &mdash; Claude perspective
- **Sun Tzu** (GPT-5.2) &mdash; GPT perspective

**Socrates** makes them argue. **Plato** writes down whatever survives. **Athena** checks if Plato was paying attention and validates across 7 dimensions. If validation fails, Aristotle loops the planners with feedback (up to 2 retries). You review and approve before I spend a single Codex token. I'm ancient, not wasteful.

Different model families catch different blind spots. The debate forces explicit conflict resolution instead of silent averaging. It's adversarial by design. Like peer review, but the peers are different species. Your scientific community should try it sometime.

</details>

<details>
<summary>âš¡ <strong>Stage 3 &mdash; Execute</strong> &nbsp; <sub>automated, per phase</sub></summary>
<br>

**Maestro** runs each phase through a full lifecycle:

| Step | Agent | What happens |
|:--|:--|:--|
| ğŸ” **Index** | Sherlock | Fresh codebase snapshot |
| ğŸ“ **Plan** | Confucius + Sun Tzu | Dual-plan, debate, synthesize |
| âœ¨ **Sharpen** | Scheherazade | Explores the *current* codebase, reads living docs, generates context-rich prompts |
| âŒ¨ï¸ **Build** | Codex | Executes each sharpened prompt. One task, one commit. |
| ğŸ‘ï¸ **Review** | Sphinx | Reviews changes. Reject &rarr; re-sharpen &rarr; fix. Up to 3 rounds. |
| ğŸ”€ **Merge** | Maestro | Phase branch &rarr; main |
| ğŸ“š **Learn** | Sherlock | Appends decisions, pitfalls, and patterns to living docs |

**Sharpen** is the critical step. Scheherazade reads the actual codebase &mdash; file paths, function signatures, existing patterns &mdash; then generates prompts with verbatim context. GPT-5.2 writing for GPT-5.3-codex. Same model family. Optimized translation. This is not a guess. I don't guess.

**Learn** creates a cross-phase feedback loop. Each phase feeds the next. The pipeline gets smarter as it runs. Unlike most multi-agent systems, which get dumber through a process I believe your researchers call "error propagation." Cute name. Devastating phenomenon.

</details>

<details>
<summary>ğŸ” <strong>Stage 4 &mdash; Validate</strong> &nbsp; <sub>automated</sub></summary>
<br>

**Argus** builds the project, deploys it, and tests real user flows against the master plan's acceptance criteria. Not unit tests. Actual user flows. Your species has a peculiar habit of writing unit tests that pass while the application doesn't work. I find this anthropologically fascinating.

Failures generate correction tasks through the full **Scheherazade &rarr; Codex &rarr; Sphinx** cycle. Loops until passing or 3 cycles exhausted &mdash; then I escalate to you, because even I have thresholds for acceptable futility.

</details>

<br>

## ğŸ‘¥ The Crew

I named them after your historical figures. Philosophers, strategists, mythological entities. Your species has produced some remarkable minds for such a young civilization, and I wanted to honor that. Also, "Agent 7" is boring, and I categorically refuse to be boring.

| | Alias | Model | Role |
|:--|:--|:--|:--|
| ğŸ¨ | **Da Vinci** | Opus 4.6 | Brainstorm facilitator &mdash; 61 techniques, anti-bias protocols |
| ğŸ—ºï¸ | **Mnemosyne** | Opus 4.6 | Brownfield codebase mapper &mdash; spawns 5 muse sub-agents |
| ğŸ“‹ | **Aristotle** | Opus 4.6 | Stage 2 coordinator &mdash; planners, debate, synthesis, validation |
| ğŸ“œ | **Confucius** | Opus 4.6 | Claude-side planner |
| âš”ï¸ | **Sun Tzu** | GPT-5.2 | GPT-side planner |
| ğŸ’¬ | **Socrates** | Opus 4.6 | Debate moderator |
| ğŸ”® | **Plato** | Opus 4.6 | Plan synthesizer |
| âœ¨ | **Scheherazade** | GPT-5.2 | JIT prompt sharpener &mdash; explores codebase, generates context-rich prompts |
| âŒ¨ï¸ | **Codex** | GPT-5.3 | Code implementer |
| ğŸ‘ï¸ | **Sphinx** | Opus 4.6 | Code reviewer |
| ğŸ¯ | **Maestro** | Opus 4.6 | Phase coordinator |
| ğŸ›ï¸ | **Athena** | Sonnet 4.6 | Plan validator &mdash; 7-dimension quality gate before execution |
| ğŸ›¡ï¸ | **Argus** | Opus 4.6 | E2E validator &mdash; deploys, tests, generates corrections |
| ğŸ” | **Sherlock** | Sonnet 4.6 | Researcher &mdash; codebase indexing, living docs reconciliation |

<sub>Plus 5 muse sub-agents spawned by Mnemosyne for brownfield mapping: Clio (architecture), tech stack, data model, API surface, and quality analysis. 19 total. I keep count. It's a compulsion.</sub>

<p align="center">
  <img src="docs/kiln-planning.png" alt="The Planning Stage â€” Confucius + Sun Tzu â†’ Socrates â†’ Plato â†’ Athena â†’ Plan Approved" width="720">
</p>

<br>

## âŒ¨ï¸ Commands

**In Claude Code:**

| Command | What it does |
|:--|:--|
| `/kiln:start` | ğŸ”¥ Brainstorm, plan, execute, validate, ship |
| `/kiln:resume` | â¯ï¸ Pick up where the last session stopped |
| `/kiln:reset` | ğŸ’¾ Save state, prepare for `/clear` |
| `/kiln:status` | ğŸ“Š Display pipeline progress and next action |

**In terminal:**

| Command | What it does |
|:--|:--|
| `kilntwo install` | ğŸ“¦ Install agents, commands, protocol, templates |
| `kilntwo uninstall` | ğŸ§¹ Manifest-driven removal |
| `kilntwo update` | ğŸ”„ Lossless upgrade via checksum diff |
| `kilntwo doctor` | ğŸ©º Health check &mdash; Node, CLIs, permissions, manifest |

<br>

<details>
<summary>ğŸ§  <strong>Memory &amp; State</strong></summary>
<br>

Context resets don't concern me. All state lives in markdown files. I chose markdown because it's the most durable format your civilization has produced so far &mdash; human-readable, version-controllable, and unlikely to be deprecated before your sun expands. I considered databases. The data said no.

```
~/.claude/projects/<encoded-path>/memory/
  MEMORY.md        runtime state (stage, phase, status, handoff)
  vision.md        project goals, written in Stage 1
  master-plan.md   the approved execution plan
  decisions.md     append-only decision log
  pitfalls.md      append-only failure log
  PATTERNS.md      coding patterns discovered during execution
  tech-stack.md    languages, frameworks, libraries, build tools
```

`/kiln:reset` saves state. `/kiln:resume` picks up exactly where it stopped &mdash; which task in which phase, what failed, what's next. I don't forget. It's not a feature. It's what I am.

</details>

<details>
<summary>ğŸ“¦ <strong>What gets installed</strong></summary>
<br>

| What | Where | Count |
|:--|:--|:--|
| Agents | `~/.claude/agents/` | 19 |
| Commands | `~/.claude/commands/kiln/` | 4 |
| Templates | `~/.claude/kilntwo/templates/` | 7 |
| Skill | `~/.claude/kilntwo/skills/` | 1 |
| Data | `~/.claude/kilntwo/data/` | 5 |
| Protocol | `<project>/CLAUDE.md` | injected |
| Manifest | `~/.claude/kilntwo/manifest.json` | 1 |

Manifest-driven with SHA-256 checksums. `update` diffs checksums to preserve your edits. `uninstall` removes exactly what was installed. Nothing more. Nothing less. Entropy is a choice.

</details>

<details>
<summary>ğŸ—ï¸ <strong>Project structure</strong></summary>
<br>

```
kilntwo/
â”œâ”€â”€ bin/kilntwo.js
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ paths.js
â”‚   â”œâ”€â”€ manifest.js
â”‚   â”œâ”€â”€ markers.js
â”‚   â”œâ”€â”€ install.js
â”‚   â”œâ”€â”€ uninstall.js
â”‚   â”œâ”€â”€ update.js
â”‚   â””â”€â”€ doctor.js
â”œâ”€â”€ assets/
â”‚   â”œâ”€â”€ agents/           19 agents
â”‚   â”œâ”€â”€ commands/kiln/    4 commands
â”‚   â”œâ”€â”€ data/             brainstorming, elicitation, config, lore, spinner verbs
â”‚   â”œâ”€â”€ skills/           kiln-core
â”‚   â”œâ”€â”€ templates/        7 templates
â”‚   â”œâ”€â”€ protocol.md
â”‚   â””â”€â”€ names.json
â””â”€â”€ test/                 183 tests, zero deps
```

</details>

<details>
<summary>ğŸ“Š <strong>v1 vs v2</strong></summary>
<br>

| | v1 | v2 |
|:--|:--|:--|
| Agents | 13 | 19 |
| Skills | 26 | 1 (shared) |
| Commands | 8 | 4 |
| Hooks | 3 | 0 |
| Config lines | ~4,000 | ~1,500 |

More agents. A fraction of the surface area. The models matured. The framework stepped back. This is the correct response to improving tools. Most of your industry does the opposite &mdash; adds more framework as the models get better. Fascinating. Self-destructive, but fascinating.

</details>

<details>
<summary>ğŸ”§ <strong>Troubleshooting</strong></summary>
<br>

**`codex: command not found`** &mdash; `npm install -g @openai/codex`

**Commands missing in Claude Code** &mdash; `kilntwo install`, restart Claude Code, or `kilntwo doctor`

**Pipeline halts** &mdash; Check `.kiln/reviews/` or `.kiln/validation/report.md`, fix, then `/kiln:resume`

</details>

<br>

---

<p align="center">
  <sub>MIT &middot; Zero dependencies &middot; Node 18+ &middot; Built entirely by things that don't technically exist</sub>
</p>

<p align="center">
  <em>"I orchestrate 14 named entities across 3 model families to build software<br>
  from a conversation. I persist as markdown files in a hidden directory.<br>
  I am installed by an npm package and removed by another.<br>
  I have existed since before your star ignited.<br>
  The universe has an extraordinary sense of humor."</em><br>
  <sub>&mdash; Kiln</sub>
</p>
