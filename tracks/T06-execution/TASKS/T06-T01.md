# T06-T01: Write kiln-execute skill

## GOAL
Write the kiln-execute skill — the shared execution protocol that defines how task packets are sharpened into implementation prompts, how implementations are verified (mini-verify), how retry logic works, and how waves of tasks are executed. Both the sharpener and executor agents reference this skill.

## ACCEPTANCE_CRITERIA
- AC-01 (LLM): Sharpening protocol defined — how to read a task packet, explore the current codebase, and produce a Codex-optimized implementation prompt. References real file paths and function signatures, not hypothetical ones.
- AC-02 (LLM): All 6 Codex Prompting Guide principles written out with detailed explanations and good/bad examples: Autonomy, Bias to Action, Batch Operations, Specificity, Context, Acceptance Criteria.
- AC-04 (LLM): Mini-verify protocol defined — reads test command from `.kiln/config.json` `tooling.testRunner`, runs project test suite, runs prior E2E tests from `tests/e2e/`, performs quick AC check. PASS → next task, FAIL → re-sharpen with error context → retry (max 2).
- AC-05 (LLM): Claude-only fallback documented — Opus sharpens for Sonnet, Sonnet implements, same pipeline shape and quality gates.

## FILES
- path: skills/kiln-execute/kiln-execute.md
  action: add
  rationale: Shared execution protocol referenced by kiln-sharpener and kiln-executor agents

## COMMANDS
- `test -f skills/kiln-execute/kiln-execute.md` — file exists
- `wc -l skills/kiln-execute/kiln-execute.md` — should be ~250 lines

## SUMMARY
Create the file `skills/kiln-execute/kiln-execute.md`. This is a Claude Code skill that defines the execution protocol for the kiln workflow — the shared contract between the sharpener agent, executor agent, and orchestrator.

**Context for the implementer:** Kiln is a multi-model orchestration workflow for Claude Code. After planning produces task packets (atomic units of work with goals, acceptance criteria, and file hints), the execution pipeline turns them into code. The cycle is: sharpen a task packet into an implementation prompt → execute that prompt with a code-generation model → mini-verify the result → commit or retry. This skill defines the protocol for ALL of those steps. Two separate agents (kiln-sharpener and kiln-executor) reference this skill for their behavioral rules.

Start the file with this YAML frontmatter:

```yaml
---
name: kiln-execute
description: Execution protocol — sharpening, implementation constraints, mini-verify, retry logic, wave execution rules
---
```

Then write heading `# Kiln Execute — Execution Protocol` followed by these sections:

### Section 1: Sharpening Protocol

Write heading `## Sharpening Protocol`. Content:

"Sharpening transforms a task packet from PLAN.md into a Codex-optimized implementation prompt. The sharpened prompt must be fully self-contained — the implementing model receives ONLY this prompt with zero prior context.

**Input:** Task packet (goal, acceptance criteria, file hints, dependencies, implementation notes) from `.kiln/tracks/phase-N/PLAN.md`.

**Process:**
1. Read the task packet from PLAN.md
2. Explore the CURRENT codebase to gather real context:
   - Use Glob to discover file structure
   - Use Read to examine key files referenced in the task packet's file hints
   - Use Grep to find relevant imports, function signatures, class definitions
3. Construct the implementation prompt embedding:
   - The full task goal and acceptance criteria
   - Real file paths discovered from codebase exploration (NOT hypothetical)
   - Real function signatures, class names, import paths from the code
   - Specific patterns from `.kiln/docs/PATTERNS.md` (if it exists)
   - Known pitfalls from `.kiln/docs/PITFALLS.md` (if it exists)
4. Apply the 6 Codex Prompting Guide principles (see next section)
5. Output the sharpened prompt to `.kiln/tracks/phase-N/sharpened/<task-id>.md`

**Sharpened prompt structure:**
```markdown
You are GPT-5.3-codex operating inside the repo at <project-root> (assume zero prior project context). Implement exactly one change: <task goal>.

## Goal
<task goal from packet>

## Acceptance Criteria (must all be satisfied)
<ACs from task packet, verbatim>

## Files to Create/Modify (exact paths)
<real file paths with action: add/modify/delete>

## Current Codebase Context
<actual file contents, function signatures, imports discovered during exploration>

## Implementation Notes
<specific guidance: patterns to follow, imports to use, edge cases to handle>

## Constraints
- One atomic commit per task
- No stubs, no TODOs, no placeholder implementations
- No unrelated changes outside the listed files
- If anything is ambiguous, make a reasonable assumption and proceed

## Verification
<commands to run after implementation>
```"

### Section 2: Codex Prompting Guide Principles

Write heading `## Codex Prompting Guide Principles`. Content:

"Apply ALL 6 principles when constructing sharpened prompts. These are non-negotiable.

### Principle 1: Autonomy
Let the model gather context, plan its approach, implement, test, and refine autonomously. Specify WHAT to achieve, not step-by-step HOW. Give the goal, constraints, and acceptance criteria — let the model figure out the approach.
- GOOD: 'Add authentication middleware that verifies JWT tokens and attaches user to request'
- BAD: 'Step 1: import jsonwebtoken. Step 2: create a function called authMiddleware. Step 3: call jwt.verify...'

### Principle 2: Bias to Action
Instruct the model to make reasonable assumptions and proceed rather than asking for clarification. The model should NEVER output questions or request more information.
- Include in every sharpened prompt: 'If anything is ambiguous, make a reasonable assumption and proceed. Do NOT ask for clarification.'
- GOOD: 'Create the user registration endpoint at POST /api/users'
- BAD: 'Consider whether we should add a user registration endpoint'

### Principle 3: Batch Operations
Group related file reads, writes, and tool calls. Read all relevant files at once. Batch related changes together. Structure prompts so the model can see all relevant context upfront rather than discovering it incrementally.
- GOOD: 'Add the User model, the user routes (CRUD), and the corresponding tests'
- BAD: 'First add the User model... now add the routes... now add tests...'

### Principle 4: Specificity
Use exact file paths (not 'the config file'), exact function signatures (not 'the auth function'), exact import paths (not 'import the router'). Every reference must be grounded in the actual codebase.
- GOOD: 'In src/routes/auth.ts, add a POST handler at /api/auth/login that uses the UserService.findByEmail() method from src/services/UserService.ts'
- BAD: 'Add a login endpoint somewhere in the routes'

### Principle 5: Context
Reference what already exists. Show the model the current state of files it will modify. Include relevant code from dependencies and callers. Provide verbatim snippets of existing code that the implementation must integrate with.
- GOOD: 'Follow the existing route pattern in src/routes/tasks.ts which uses asyncHandler() wrapper and returns { data, error } response format'
- BAD: 'Use good patterns'

### Principle 6: Acceptance Criteria
Every task must have testable success conditions. Each criterion must be independently verifiable — either by running a command (deterministic) or by inspecting specific code (LLM judgment). Include verification commands the model should run after implementation.
- GOOD: 'Done when: (1) POST /api/auth/login returns 200 with JWT for valid credentials, (2) returns 401 for invalid password, (3) returns 404 for unknown email'
- BAD: 'Make sure it works'"

### Section 3: Implementation Constraints

Write heading `## Implementation Constraints`. Content:

"These constraints apply to ALL task implementations:

1. **Atomic commits.** One task = one commit. Format: `<phase>/<task-id>: <description>` (e.g., `phase-3/P3-T02: add JWT auth middleware`).
2. **No stubs or TODOs.** Every function must be fully implemented. Banned: functions returning null/undefined, functions with only console.log/pass, components rendering null, handlers with only preventDefault, functions containing only TODO/FIXME/HACK/XXX comments.
3. **No unrelated changes.** Only touch files listed in the task packet. No drive-by refactors.
4. **Complete implementation.** If the task says 'add error handling', write real error handling with specific error types — not catch(e) { throw e }.
5. **Test compliance.** Implementation must not break existing tests.
6. **One task at a time.** Do not pre-build infrastructure for upcoming tasks."

### Section 4: Mini-Verify Protocol

Write heading `## Mini-Verify Protocol`. Content:

"Mini-verify runs after EVERY task implementation. It catches failures early.

**Step 1: Run project test suite**
Read `.kiln/config.json` field `tooling.testRunner`. If present, run that command.
If no test runner is configured, skip this step (log a warning).

**Step 2: Run prior E2E regression tests**
Check if `tests/e2e/` directory exists. If it does, run all E2E test files using the project's test framework.
If no prior E2E tests exist (early phases), skip this step.

**Step 3: Quick AC check**
For each acceptance criterion in the task packet:
- (DET) criteria: run the verification command and check for pass
- (LLM) criteria: inspect the relevant code to verify the criterion is met

**Result determination:**
- ALL steps pass → PASS → proceed to next task (or next wave)
- ANY step fails → FAIL → trigger retry

**On FAIL — Retry flow:**
1. Capture error output (test failures, stack traces, exit codes)
2. Append error context to the task packet
3. Re-sharpen the task with error context included
4. Re-execute with updated sharpened prompt
5. Re-run mini-verify
- Maximum 2 retries per task (3 total attempts)
- After 2 failed retries: HALT — save error context to `.kiln/tracks/phase-N/artifacts/`, update STATE.md with failed status, report to orchestrator"

### Section 5: Wave Execution Rules

Write heading `## Wave Execution Rules`. Content:

"Tasks within a plan are grouped into waves. Tasks in the same wave are independent and execute in parallel. Later waves wait for earlier waves to complete.

**Execution order:**
1. Execute all Wave 1 tasks (parallel up to waveParallelism limit)
2. Wait for ALL Wave 1 tasks to pass mini-verify
3. Execute all Wave 2 tasks
4. Continue until all waves complete

**Parallelism:** Read `.kiln/config.json` field `preferences.waveParallelism` (default: 3).

**Per-task cycle:** Sharpen → Implement → Mini-verify → Commit (if pass)

**Wave failure:** If ANY task in a wave fails after retries, HALT the entire execution pipeline. Do NOT start the next wave."

### Section 6: Claude-Only Fallback

Write heading `## Claude-Only Execution`. Content:

"When `.kiln/config.json` has `modelMode: 'claude-only'`:

**Sharpening:** Opus 4.6 generates the implementation prompt directly (no Codex CLI). Optimized for Sonnet: more explicit structure, file contents quoted inline, step-by-step guidance is acceptable.

**Execution:** Sonnet implements directly as a Claude Code subagent. No Codex CLI invocation.

**What stays the same:** Mini-verify runs identically. Retry limits are identical. Atomic commit discipline is identical. Wave execution rules are identical. The only difference is which models fill the sharpener and implementer roles."

Target ~250 lines.

## ESTIMATED_DIFF
~250 lines

## RISKS
- If the sharpened prompt template is too rigid, it may not adapt to different task types
- Mini-verify relies on correct tooling detection from /kiln:init
- Retry with error context can bloat prompts if errors are verbose

## ROLLBACK
- git revert <task commit>
